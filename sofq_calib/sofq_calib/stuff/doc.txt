!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
This page contains detailed explanation about why we may 
or may not need to calibrate the S(Q) data.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

In principle, the wavelength of neutron can be determined by the flying distance (from source to detector) and flying time, assuming elastic scattering (see, e.g. chapter-5 in S. Billinge's book on diffuse scattering). However, in practice, such a standard relation cannot be used to pin down the wavelength thus absolute value of Q. The main reason is that the exact position of sample is actually unknown and more obviously, the real sample will never be an ideal point (located at exactly the intersection point between the incoming and scattered neutron beam). Therefore, in practice we need to use a standard sample (e.g. diamond) - for which we know exactly the lattice parameters and which scatters well (e.g. diamond gives sharp and strong scattering peaks) - to calibrate the time-of-flight (TOF) data. That means we want to establish the transformation from TOF to Q. For example, using mantid for processing NOMAD total scattering data, a simple refinement (for multiple peaks) will be carried out for scattering pattern coming out from each pixel (detector), taking into account of both peak profiles and peak position (i.e. co-refinement of peak profile and peak position, like we usually do in Rietveld refinement). Following the standard parameterized way of transforming between TOF and Q, we have three parameters - difc, difa and dzero. Then the three parameters can be adjusted (again, together with peak profiles in the process of co-refinement) to match the well-known lattice parameter of diamond. Now we have the TOF-to-Q transformation well established (for each single detector/pixel), and we can then put scattering patterns from all pixels on top of each other and merge them. Wihtout the diamond calibration, a simple overlay of scattering patterns from all pixels will not work because they are not aligned up. At this point, we get the final total scattering pattern (obviously we need more reduction steps such as normalization by vanadium, multiple scattering, absorption and Plazcek correction, which will not be covered here). Apart from the total scattering pattern, we also have the Bragg data at the same time. However, what we usually use for Bragg data as x-axis is not Q, but TOF instead. The reason is that usually for Bragg refinement (say, Rietveld refinement), we tend to use Si Bragg pattern as the reference, from which we can obtain the difc, difa and dzero values through refinement for Bragg pattern of Si standard. Here, a question pops up immediately. As mentioned above, we transform the TOF data into Q-space to obtain the total scattering pattern. But now we need Bragg data in TOF space, how do we obtain the TOF Bragg data? Well at first sight, we may (at least I did) think that's not a problem since orginally what's coming out from the raw measurement is just TOF data. Can't we just use that??? The answer is obviously NO, because, as we mentioned, the very original TOF data obtained on each pixel/detector does not align up (and that's why we use diamond to calibrate before merging them together). Therefore, we don't even have a raw merged data in TOF space. But we do have a raw merged data in Q space after the diamond calibration. From there, we want to transform the Bragg data back into TOF space for refinements. With this regards, a single difc value for each bank is usually used for the corresponding tranformation from Q to TOF space. Why a single difc value but not using difc, difa and dzero? The answer is that we now know the Q value through diamond calibration, and going back into TOF space is just a temporary transformation and the TOF values in this case does not have to be anything real/meaningful. Suppose we are doing usual Rietveld refinement for both our sample and Si standard. We intend to use Si standard for calibrating the TOF-to-Q transformation for the refinement. In this case, the absolute value of TOF does not matter at all if we keep consistence between our sample and Si standard.

Furthermore, we have another question to address. Since we have already established the TOF-to-Q transformation through diamond calibration, why canâ€™t we just use the obtained Q-space pattern to directly do the Rietveld refinement (either bank by bank or the merged S(Q) as a whole)? Well, if we can define a proper peak profile in Q-space, for sure we can do that and in fact this has already been done by Jue Liu (beamline scientist at NOMAD diffractometer at SNS, ORNL). But usually people don't do that and instead Bragg refinement is usually done in TOF space with a standard sample (e.g. NIST Si) as the reference for calibrating TOF-to-Q transformation. In such a situation, even assuming the originally established TOF-to-Q transformation (through diamond calibration) is wrong, we are still fine if we follow the conventional calibration scheme of Bragg refinement. The rationale is that even the absolute value of Q or TOF is incorrect, the incorrectness in between our sample and Si is systematic and consistent. Then using, e.g. Si, as the reference, we will know for sure the transformation from the 'incorrect' TOF to Q, which will finally bring us to the right Q position ANYWAYS.

In general, we cannot directly say which calibration - either the initial one with diamond (during data reduction) or that with Si (during later Bragg refinement) - is right or wrong. They are just two different approaches of doing the calibration using different standard as the reference (as mentioned, using diamond as calibration reference for total scattering is because it scatters strongly and sharply). Probably the only thing we can say is the inconsistency in between such two ways of doing calibration is understandable and acceptable. For example, the lattice parameters obtained from Rietveld and PDF refinement often is not consistent with each other, which, as we mentioned, is unstandable and acceptable. At least, within the framework of either PDF or Bragg analysis themselves, things are indeed consistent, internally. However, specifically for our implementation of resolution correction by establishing the resolution matrix through Si Bragg refinement, we base ourselves on the assumption that the peak profiles of Si standard purely comes from the instrument. Then we grab the obtained resolution matrix and convolute it into the calculated S(Q) pattern. At this point, we have to make sure that the consistency of Q point assignment between total scattering and Bragg pattern. Here is the place where current GUI can come to help.
